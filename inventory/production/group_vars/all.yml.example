---
# =============================================================================
# HOMELAB K3S CLUSTER CONFIGURATION
# High-Resource Cluster: 5 nodes, 36 CPU cores, ~250GB RAM
# =============================================================================

ansible_python_interpreter: /usr/bin/python3

# K3s and Kubeconfig settings
k3s_server_path: /etc/rancher/k3s/k3s.yaml

# =============================================================================
# CORE INFRASTRUCTURE
# =============================================================================

# K3s Configuration
k3s_version: v1.33.1+k3s1
k3s_state: present

# Kubeconfig Management
kubeconfig_dir: "{{ playbook_dir }}/../fetched_tokens"
kubeconfig_path: "{{ kubeconfig_dir }}/k3s-kubeconfig"
control_plane_host: "{{ groups['k3s_control_plane'][0] }}"
control_plane_ip: "{{ hostvars[groups['k3s_control_plane'][0]]['ansible_host'] }}"

# Network Configuration
k3s_pod_cidr: "10.42.0.0/16"
k3s_service_cidr: "10.43.0.0/16"
k3s_api_port: 6443

# Storage
global_storage_class: "nfs-shared"
nfs_server_ip: "{{ hostvars[groups['nfs_server'][0]]['ansible_host'] }}"
nfs_path: "/srv/nfs/kubernetes"
nfs_allowed_networks: "192.168.1.0/24"

# =============================================================================
# OPTIMIZED RESOURCE ALLOCATION FOR HIGH-RESOURCE HOMELAB
# =============================================================================

# MinIO - High-Performance Storage
minio_namespace: "minio"
minio_nodeport: 30900
minio_console_nodeport: 30901
minio_memory_request: "8Gi"
minio_memory_limit: "16Gi"
minio_cpu_request: 4
minio_cpu_limit: 8
minio_storage_size: "1Ti"
minio_internal_endpoint: "http://minio.minio.svc.cluster.local:9000"

# Grafana - High-Performance Dashboards  
grafana_nodeport: 30300
grafana_admin_user: "admin"
grafana_admin_password: "admin123"
grafana_memory_request: "4Gi"
grafana_memory_limit: "8Gi"
grafana_cpu_request: 2
grafana_cpu_limit: 4
grafana_storage_size: "100Gi"

# MLflow - Enhanced ML Experiment Tracking
mlflow_namespace: "mlflow"
mlflow_nodeport: 30800
mlflow_image: "jtayl22/mlflow-postgresql:2.17.2"
mlflow_storage_size: "500Gi"
mlflow_memory_request: "8Gi"
mlflow_memory_limit: "16Gi"
mlflow_cpu_request: 4
mlflow_cpu_limit: 8
mlflow_s3_bucket: "mlflow-artifacts"
mlflow_s3_endpoint: "http://minio.minio.svc.cluster.local:9000"
mlflow_storage_class: "{{ global_storage_class }}"

# External PostgreSQL Configuration for MLflow
mlflow_db_enabled: true
mlflow_db_host: "192.168.1.100"
mlflow_db_port: "5432"  
mlflow_db_name: "mlflow"
mlflow_db_username: "mlflow"
mlflow_db_password: "{{ vault_mlflow_db_password | default('mlflow-secure-password-123') }}"

# MLflow Configuration (updated)
mlflow_backend_store_type: "postgresql"  # Changed from file-based
mlflow_enable_model_registry: true       # Enable Model Registry features

# Seldon Core - High-Performance Model Serving
seldon_namespace: "seldon-system"
seldon_chart_repo: "https://storage.googleapis.com/seldon-charts"
seldon_chart_repo_name: "seldon"
seldon_chart_name: "seldon-core-operator"
seldon_memory_request: "4Gi"
seldon_memory_limit: "12Gi"
seldon_cpu_request: 2
seldon_cpu_limit: 8
seldon_minio_bucket: "seldon-models"
seldon_enable_analytics: true

# JupyterHub - High-Performance Data Science Environment
jupyterhub_namespace: "jupyterhub"
jupyterhub_nodeport: 30888
jupyterhub_password: "mlops123"
# Enhanced user resources for heavy ML workloads
jupyterhub_user_memory_request: "4Gi"
jupyterhub_user_memory_limit: "16Gi"
jupyterhub_user_cpu_request: 1.0
jupyterhub_user_cpu_limit: 8.0
jupyterhub_storage_type: "dynamic"
jupyterhub_storage_size: "50Gi"

# Argo Workflows - High-Performance Pipeline Execution
argowf_namespace: "argowf"
argowf_nodeport: 32746
argowf_username: "admin"
argowf_password: "mlopsadmin123"
# Enhanced resources for ML pipeline execution
argowf_memory_request: "2Gi"
argowf_memory_limit: "8Gi"
argowf_cpu_request: 1
argowf_cpu_limit: 4

# Kubernetes Dashboard
dashboard_nodeport: 30444

# =============================================================================
# ELASTICSEARCH STACK (OPTIONAL - HIGH RESOURCE USAGE)
# =============================================================================

elasticsearch_namespace: "elastic"
elasticsearch_node_count: 2
elasticsearch_memory_request: "8Gi"
elasticsearch_memory_limit: "16Gi"
elasticsearch_cpu_request: "2"
elasticsearch_cpu_limit: "4"
elasticsearch_storage_size: "200Gi"

# =============================================================================
# SECURITY & NETWORKING
# =============================================================================

# Sealed Secrets
sealed_secrets_namespace: "kube-system"
sealed_secrets_controller_name: "sealed-secrets"

# UFW Firewall
configure_ufw: true
ufw_default_policy_incoming: deny
ufw_default_policy_outgoing: allow

# =============================================================================
# FEATURE FLAGS FOR HOMELAB OPTIMIZATION
# =============================================================================

# Enable/Disable heavy components based on needs
enable_elasticsearch: false
enable_kubeflow: false
enable_istio: true
enable_advanced_monitoring: true
enable_gpu_support: false

# Development vs Production modes
homelab_mode: true
development_mode: true
high_availability: false

# Add these Prometheus Pushgateway variables to your existing monitoring section

# Prometheus Stack Configuration
prometheus_stack_namespace: "monitoring"
prometheus_stack_name: "prometheus-stack"
prometheus_stack_chart_ref: "prometheus-community/kube-prometheus-stack"
prometheus_nodeport: 30090
prometheus_storage_class: "{{ global_storage_class }}"
prometheus_storage_size: "50Gi"
prometheus_memory_request: "4Gi"
prometheus_memory_limit: "8Gi"
prometheus_cpu_request: 2
prometheus_cpu_limit: 4

# Prometheus Pushgateway Configuration
pushgateway_nodeport: 32091
pushgateway_memory_request: "128Mi"
pushgateway_memory_limit: "512Mi"
pushgateway_cpu_request: "100m"
pushgateway_cpu_limit: "500m"

# Helm Configuration
helm_wait_timeout: 600s
helm_retries: 3
helm_retry_delay: 10

# Istio Configuration
istio_gateway_http_nodeport: 31080
istio_gateway_https_nodeport: 31443
istio_pilot_memory_request: "128Mi"
istio_pilot_memory_limit: "512Mi" 
istio_pilot_cpu_request: "100m"
istio_pilot_cpu_limit: "500m"
istio_gateway_memory_request: "128Mi"
istio_gateway_memory_limit: "512Mi"
istio_gateway_cpu_request: "100m"
istio_gateway_cpu_limit: "500m"

# KServe Configuration - Fix namespace to match actual installation
kserve_namespace: "kserve"  # Changed from "kserve-system" to "kserve"
kserve_version: "0.15.0"
knative_version: "1.15.0"
kserve_controller_memory_request: "256Mi"
kserve_controller_memory_limit: "1Gi"
kserve_controller_cpu_request: "100m"
kserve_controller_cpu_limit: "1000m"

# Cert Manager Configuration
certmanager_memory_request: "128Mi"
certmanager_memory_limit: "512Mi"
certmanager_cpu_request: "100m"
certmanager_cpu_limit: "500m"

# Node affinity and scheduling configuration
enable_worker_node_scheduling: true
prefer_worker_nodes_for_jobs: true
control_plane_scheduling_weight: 50  # Lower weight = less preferred
worker_node_scheduling_weight: 100   # Higher weight = more preferred

# PostgreSQL Configuration
postgresql_enabled: true
postgresql_name: postgresql
postgresql_namespace: postgresql
postgresql_chart_ref: bitnami/postgresql
postgresql_chart_version: "15.5.20"
postgresql_version: "15.8.0"

# PostgreSQL Authentication
postgresql_postgres_password: "{{ vault_postgresql_postgres_password | default('postgres-admin-password-123') }}"
postgresql_mlflow_username: mlflow
postgresql_mlflow_password: "{{ vault_postgresql_mlflow_password | default('mlflow-password-123') }}"
postgresql_mlflow_database: mlflow

# PostgreSQL Resources
postgresql_storage_size: 20Gi
postgresql_storage_class: "{{ global_storage_class }}"
postgresql_memory_request: 512Mi
postgresql_memory_limit: 1Gi
postgresql_cpu_request: 250m
postgresql_cpu_limit: 500m
